{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-grid-search-sarima-model-hyperparameters-for-time-series-forecasting-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# one-step sarima forecast\n",
    "def sarima_forecast(history, config):\n",
    "    order, sorder, trend = config\n",
    "    # define model\n",
    "    model = SARIMAX(\n",
    "        history,\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        trend=trend,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "    )\n",
    "    # fit model\n",
    "    model_fit = model.fit(disp=False)\n",
    "    # make one step forecast\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    return yhat[0]\n",
    "\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = sarima_forecast(history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    return error\n",
    "\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "    result = None\n",
    "    # convert config to a key\n",
    "    key = str(cfg)\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        result = walk_forward_validation(data, n_test, cfg)\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "            # never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                result = walk_forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "    # check for an interesting result\n",
    "    if result is not None:\n",
    "        print(\" > Model[%s] %.3f\" % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "        # execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend=\"multiprocessing\")\n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "\n",
    "# create a set of sarima configs to try\n",
    "def sarima_configs(seasonal=[0]):\n",
    "    models = list()\n",
    "    # define config lists\n",
    "    p_params = [0, 1, 2]\n",
    "    d_params = [0, 1]\n",
    "    q_params = [0, 1, 2]\n",
    "    t_params = [\"n\", \"c\", \"t\", \"ct\"]\n",
    "    P_params = [0, 1, 2]\n",
    "    D_params = [0, 1]\n",
    "    Q_params = [0, 1, 2]\n",
    "    m_params = seasonal\n",
    "    # create config instances\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for t in t_params:\n",
    "                    for P in P_params:\n",
    "                        for D in D_params:\n",
    "                            for Q in Q_params:\n",
    "                                for m in m_params:\n",
    "                                    cfg = [(p, d, q), (P, D, Q, m), t]\n",
    "                                    models.append(cfg)\n",
    "    return models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Sprint_Resampled Data.csv\")\n",
    "df['Date'] = df['Date'].apply(pd.to_datetime)\n",
    "df = df.set_index('Date')\n",
    "df.columns\n",
    "df = df[\"Cushing, OK WTI Spot Price FOB (Dollars per Barrel)\"]\n",
    "df = df.dropna()\n",
    "df = df['1991' : '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model[[(0, 0, 0), (0, 0, 0, 0), 'n']] 58.951\n",
      " > Model[[(0, 0, 0), (0, 0, 0, 12), 'n']] 58.951\n",
      " > Model[[(0, 0, 0), (0, 0, 1, 0), 'n']] 29.842\n",
      " > Model[[(0, 0, 0), (0, 1, 0, 12), 'n']] 11.949\n",
      " > Model[[(0, 0, 0), (0, 0, 1, 12), 'n']] 29.266\n",
      " > Model[[(0, 0, 0), (0, 0, 2, 0), 'n']] 18.015\n",
      " > Model[[(0, 0, 0), (1, 0, 0, 0), 'n']] 5.555\n",
      " > Model[[(0, 0, 0), (1, 0, 0, 12), 'n']] 11.240\n",
      " > Model[[(0, 0, 0), (0, 1, 1, 12), 'n']] 9.236\n",
      " > Model[[(0, 0, 0), (1, 0, 1, 0), 'n']] 5.253\n",
      " > Model[[(0, 0, 0), (1, 0, 2, 0), 'n']] 5.648\n",
      " > Model[[(0, 0, 0), (1, 0, 1, 12), 'n']] 9.388\n",
      " > Model[[(0, 0, 0), (1, 1, 0, 12), 'n']] 9.912\n",
      " > Model[[(0, 0, 0), (0, 0, 2, 12), 'n']] 23.591\n",
      " > Model[[(0, 0, 0), (0, 1, 2, 12), 'n']] 9.244\n",
      " > Model[[(0, 0, 0), (2, 0, 0, 0), 'n']] 5.435\n",
      " > Model[[(0, 0, 0), (1, 0, 2, 12), 'n']] 9.410\n",
      " > Model[[(0, 0, 0), (2, 0, 0, 12), 'n']] 9.947\n",
      " > Model[[(0, 0, 0), (1, 1, 1, 12), 'n']] 9.236\n",
      " > Model[[(0, 0, 0), (2, 0, 1, 0), 'n']] 5.510\n",
      " > Model[[(0, 0, 0), (2, 0, 2, 0), 'n']] 5.631\n",
      " > Model[[(0, 0, 0), (2, 1, 0, 12), 'n']] 9.619\n",
      " > Model[[(0, 0, 0), (2, 0, 1, 12), 'n']] 9.555\n",
      " > Model[[(0, 0, 0), (1, 1, 2, 12), 'n']] 9.234\n",
      " > Model[[(0, 0, 0), (2, 0, 2, 12), 'n']] 9.346\n",
      " > Model[[(0, 0, 0), (0, 0, 0, 0), 'c']] 12.143\n",
      " > Model[[(0, 0, 0), (0, 0, 0, 12), 'c']] 12.143\n",
      " > Model[[(0, 0, 0), (0, 0, 1, 0), 'c']] 6.797\n",
      " > Model[[(0, 0, 0), (0, 0, 1, 12), 'c']] 10.076\n",
      " > Model[[(0, 0, 0), (2, 1, 1, 12), 'n']] 9.720\n",
      " > Model[[(0, 0, 0), (0, 1, 0, 12), 'c']] 12.499\n",
      " > Model[[(0, 0, 0), (0, 0, 2, 0), 'c']] 6.307\n",
      " > Model[[(0, 0, 0), (0, 1, 1, 12), 'c']] 9.252\n",
      " > Model[[(0, 0, 0), (1, 0, 0, 0), 'c']] 5.537\n",
      " > Model[[(0, 0, 0), (0, 0, 2, 12), 'c']] 7.823\n",
      " > Model[[(0, 0, 0), (1, 0, 0, 12), 'c']] 10.410\n",
      " > Model[[(0, 0, 0), (2, 1, 2, 12), 'n']] 9.237\n",
      " > Model[[(0, 0, 0), (1, 0, 1, 0), 'c']] 5.224\n",
      " > Model[[(0, 0, 0), (1, 0, 1, 12), 'c']] 9.011\n",
      " > Model[[(0, 0, 0), (0, 1, 2, 12), 'c']] 9.400\n",
      " > Model[[(0, 0, 0), (1, 1, 0, 12), 'c']] 10.025\n",
      " > Model[[(0, 0, 0), (1, 0, 2, 0), 'c']] 5.606\n",
      " > Model[[(0, 0, 0), (2, 0, 0, 0), 'c']] 5.397\n",
      " > Model[[(0, 0, 0), (1, 1, 1, 12), 'c']] 9.251\n",
      " > Model[[(0, 0, 0), (2, 0, 0, 12), 'c']] 9.335\n",
      " > Model[[(0, 0, 0), (1, 0, 2, 12), 'c']] 8.997\n",
      " > Model[[(0, 0, 0), (2, 0, 1, 0), 'c']] 5.217\n",
      " > Model[[(0, 0, 0), (2, 0, 2, 0), 'c']] 5.581\n",
      " > Model[[(0, 0, 0), (1, 1, 2, 12), 'c']] 9.483\n",
      " > Model[[(0, 0, 0), (2, 0, 1, 12), 'c']] 9.228\n",
      " > Model[[(0, 0, 0), (2, 1, 0, 12), 'c']] 9.500\n",
      " > Model[[(0, 0, 0), (0, 0, 0, 0), 't']] 33.339\n",
      " > Model[[(0, 0, 0), (0, 0, 0, 12), 't']] 33.339\n",
      " > Model[[(0, 0, 0), (0, 0, 1, 0), 't']] 17.950\n",
      " > Model[[(0, 0, 0), (0, 0, 1, 12), 't']] 26.722\n",
      " > Model[[(0, 0, 0), (2, 0, 2, 12), 'c']] 9.228\n",
      " > Model[[(0, 0, 0), (0, 0, 2, 0), 't']] 12.120\n",
      " > Model[[(0, 0, 0), (0, 1, 0, 12), 't']] 12.511\n",
      " > Model[[(0, 0, 0), (2, 1, 1, 12), 'c']] 9.506\n",
      " > Model[[(0, 0, 0), (0, 0, 2, 12), 't']] 24.432\n",
      " > Model[[(0, 0, 0), (1, 0, 0, 0), 't']] 5.747\n",
      " > Model[[(0, 0, 0), (0, 1, 1, 12), 't']] 9.360\n",
      " > Model[[(0, 0, 0), (1, 0, 0, 12), 't']] 18.467\n",
      " > Model[[(0, 0, 0), (1, 0, 1, 0), 't']] 5.425\n",
      " > Model[[(0, 0, 0), (1, 0, 1, 12), 't']] 16.822\n",
      " > Model[[(0, 0, 0), (1, 0, 2, 0), 't']] 5.816\n",
      " > Model[[(0, 0, 0), (0, 1, 2, 12), 't']] 9.402\n",
      " > Model[[(0, 0, 0), (2, 1, 2, 12), 'c']] 9.586\n",
      " > Model[[(0, 0, 0), (1, 1, 0, 12), 't']] 10.063\n",
      " > Model[[(0, 0, 0), (2, 0, 0, 0), 't']] 5.608\n",
      " > Model[[(0, 0, 0), (1, 0, 2, 12), 't']] 18.487\n",
      " > Model[[(0, 0, 0), (2, 0, 0, 12), 't']] 16.342\n",
      " > Model[[(0, 0, 0), (1, 1, 1, 12), 't']] 9.361\n",
      " > Model[[(0, 0, 0), (2, 0, 1, 0), 't']] 5.710\n",
      " > Model[[(0, 0, 0), (2, 0, 2, 0), 't']] 5.770\n",
      " > Model[[(0, 0, 0), (2, 0, 1, 12), 't']] 16.459\n",
      " > Model[[(0, 0, 0), (1, 1, 2, 12), 't']] 9.382\n"
     ]
    }
   ],
   "source": [
    "data = df.values\n",
    "# trim dataset to 5 years\n",
    "result = []\n",
    "# data split\n",
    "n_test = 12\n",
    "# model configs\n",
    "cfg_list = sarima_configs(seasonal=[0, 12])\n",
    "# grid search\n",
    "scores = grid_search(data, cfg_list, n_test)\n",
    "print('done')\n",
    "# list top 3 configs\n",
    "for cfg, error in scores[:3]:\n",
    "    result.add(ctg,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
